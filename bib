#!/usr/bin/env python3
"""\b
BibTeX database utilities
© 2016–2018 Paul Natsuo Kishimoto <mail@paul.kishimoto.name>
Licensed under the GNU GPL v3.

Reads a file .bibpy.yaml in the current directory or in PATH that may contain
general or command-specific keys. The only general configuration key is:

database: same as the --database option.

The following commands have command-specific keys. For these, use a top-level
key with the command name, and then place command-specific keys underneath. Use
'bib COMMAND --help' to see documentation about these keys.

\b
- check_files
- import
- queue
"""
# TODO fix abstracts do not save correctly if not in DB directory
# TODO speed up loading/defer reading of the database until it's needed/read in
#      a separate thread
from collections import namedtuple
from copy import deepcopy
from datetime import datetime
from glob import iglob
from itertools import chain, filterfalse, zip_longest
import os
import os.path
import re
import readline

import bibtexparser
from bibtexparser.customization import author
from bibtexparser.bparser import BibTexParser
from bibtexparser.bwriter import BibTexWriter
import click
from click import ClickException
from dialog import Dialog
import yaml


DEFAULT_CONFIG = {
    'kw_sep': ',|;',
    'lf_sep': ';',
    }


class BibItem(dict):
    """Biliography items."""

    def __init__(self, record, add_keywords, config):
        # Parse 'keywords' to a list
        if 'keywords' in record:
            record['keywords'] = [kw.strip() for kw in
                                  re.split(config['kw_sep'],
                                           record['keywords'])]
            add_keywords(record['keywords'])

        # Parse 'localfile' to a list
        if 'localfile' in record:
            record['localfile'] = [lf.strip() for lf in
                                   re.split(config['lf_sep'],
                                            record['localfile'])]

        dict.__init__(self, record)
        self.type = self['ENTRYTYPE']

    @property
    def has_file(self):
        return 'localfile' in self

    @property
    def file_exists(self):
        if type(self['localfile']) == list:
            return all([os.path.exists(lf) for lf in self['localfile']])
        else:
            return os.path.exists(self['localfile'])

    def file_rel_path(self):
        if type(self['localfile']) == list:
            return [os.path.relpath(lf) for lf in self['localfile']]
        else:
            return os.path.relpath(self['localfile'])

    def stringify(self):
        """Convert all entries to strings.

        bibtexparser.bwriter.BibTexWriter requires all records in an item
        to be strings.
        """
        try:
            self['keywords'] = ';'.join(self['keywords'])
        except KeyError:
            pass


class BibCLIContext:
    def __init__(self):
        self.config = DEFAULT_CONFIG

        self.keywords = set()

    def init(self, database, verbose, path):
        try:
            config_fn = os.path.join(path, '.bibpy.yaml')
            with open(config_fn) as f:
                self.config.update(yaml.load(f))
            self.config['path'] = path
        except FileNotFoundError:
            pass

        if database:
            self.config['database'] = database

        self.verbose = verbose

        # Parse the database
        self.database_fn = os.path.join(path, self.config['database'])
        self.db = self.read_database(self.database_fn)

    def cmd_config(self, cmd):
        return self.config.get(cmd, {})

    def read_database(self, filename):
        # Set up the BibTeX parser
        parser = BibTexParser()
        parser.homogenise_fields = False
        parser.ignore_nonstandard_types = False
        parser.customization = lambda r: BibItem(r,
                                                 self.keywords.update,
                                                 self.config)
        return bibtexparser.load(open(filename, 'r'), parser=parser)


# Custom decorator that uses BibCLIContext
pass_context = click.make_pass_decorator(BibCLIContext, ensure=True)


@click.group(help=__doc__)
@click.option('--database', type=click.Path('r'),
              help='Filename for the BibTeX database.')
@click.option('--verbose', is_flag=True, help='More detailed output.')
@click.option('--path', 'path', type=click.Path('r'),
              envvar='BIBPY_PATH', default='.',
              help='Path to the folder containing the database.')
@pass_context
def cli(ctx, database, verbose, path):
    # Initialize the context (load the database)
    ctx.init(database, verbose, path)


def _add_clean(d):
    """Custom entry cleaning for add()."""

    # Delete the leading text 'ABSTRACT'
    if 'abstract' in d and d['abstract'].lower().startswith('abstract'):
        d['abstract'] = d['abstract'][8:].strip()

    d['author'] = d['author'].replace('\n', ' ')

    if 'doi' in d:
        # Show a bare DOI, not a URL
        d['doi'] = re.sub('https?://(dx.)?doi.org/', '', d['doi'])
        # Don't show eprint or url fields if a DOI is present
        # (e.g ScienceDirect)
        d.pop('eprint', None)
        d.pop('url', None)

    # BibLaTeX: use 'journaltitle' for the name of the journal
    if 'journal' in d:
        d['journaltitle'] = d.pop('journal')

    if 'pages' in d:
        # Pages: use an en-dash
        d['pages'] = d['pages'].replace('--', '–').replace('-', '–') \
                               .replace(' ', '')

    # Delete any empty fields or those containing '0'
    for k in list(d.keys()):
        if d[k] in ['0', '']:
            del d[k]

    return d


def guess_key(entry):
    entry = author(deepcopy(entry))
    if len(entry['author']) > 2:
        a = entry['author'][0].split(',')[0].lower()
    else:
        a = '-'.join([a.split(',')[0].lower() for a in entry['author']])

    # Use YYYY if the year is not present
    year = entry.get('year', 'YYYY')

    return f'{a}-{year}'


def clean_str(s):
    # Add a trailing comma on the last entry:
    # https://github.com/sciunto-org/python-bibtexparser/issues/47
    s = re.sub(r'([^,])(\s*}\s*)\Z', r'\1,\2', s)
    # Compress multiple 'keywords'
    parts = re.split(r'(keywords)\s=\s[{"]([^}"]*)[}"],', s)
    result = ''
    keywords = []
    take = False
    for p in parts:
        if p == 'keywords':
            take = True
            continue
        elif take:
            keywords.append(p)
            take = False
            continue
        elif p.strip() == '':
            continue

        if len(keywords):
            result += 'keywords = {%s},' % '; '.join(keywords)

        # DEBUG print the parts
        # print('part: <%s>' % p)

        result += p

    return result


# https://stackoverflow.com/a/8505387/2362198
def input_with_prefill(prompt, text):
    def hook():
        readline.insert_text(text)
        readline.redisplay()
    readline.set_pre_input_hook(hook)
    result = input(prompt)
    readline.set_pre_input_hook()
    return result


def _select_file(key, path):
    """Select a file from the directory containing *path*.

    A command-line dialog is displayed. *key* is used to prompt the user.
    """

    start = os.path.join(os.path.dirname(path), '.')

    d = Dialog()
    lines, cols = d.maxsize()
    args = dict(
        cancel_label='No file',
        height=lines-10,
        width=cols,
        no_shadow=True,
        no_lines=True,
        title='Select a file for entry: {}'.format(key))

    while True:
        result, target = d.fselect(start, **args)
        if target != start:
            break

    os.system('clear')

    if result == 'ok':
        return target
    else:
        return None


@cli.command(name='import')
@click.argument('paths', nargs=-1, type=click.Path(exists=True))
@pass_context
def import_entries(ctx, paths):
    """(DEV) Read new entries into the database.

    PATHS may be zero or more .bib files or directories containing .bib files
    to import.


    Configuration File Keys

    \b
    import:
      path: a default path to check for .bib files to import, if no PATHS are
            given.
    """
    # If no files
    if len(paths) == 0:
        # Directory from which to import entries
        paths = [ctx.cmd_config('import').get('path', '.')]

    paths = [os.path.join(p, '*.bib') if os.path.isdir(p) else p
             for p in paths]

    # A parser for reading entries
    parser = BibTexParser()
    parser.homogenise_fields = False
    parser.customization = _add_clean

    # A writer for converting entries back to strings
    writer = BibTexWriter()
    writer.indent = '\t'

    # namedtuple to imitate a class with these attributes
    _dbnt = namedtuple('bdb', ['comments', 'entries', 'preambles', 'strings'])

    def to_string(entry):
        """Convert [entry] to a string."""
        # Create a fake 'database' with only one entry.
        return writer.write(_dbnt([], [entry], [], {}))

    # Iterate over files in the add_dir
    for fn in chain(*map(iglob, paths)):
        os.system('clear')
        print('Importing', fn, end='\n\n')

        # Read and parse the file
        with open(fn, 'r') as f:
            s = f.read()
            e = parser.parse(clean_str(s)).entries[-1]
            abstract = e.pop('abstract', None)

        print('Raw:', s)
        print('Entry:', to_string(e), sep='\n\n')

        if abstract is not None:
            print('Abstract:', abstract, sep='\n\n')

        # Ask user for a key
        while True:
            key = input_with_prefill('\nEnter key for imported entry '
                                     '(blank to skip, [Q]uit): ',
                                     guess_key(e))
            if key in ctx.db.entries_dict:
                print('Key already exists.')
            else:
                break

        if key == '':
            continue
        elif key.lower() == 'q':
            break
        else:
            # Change the entry key
            e['ID'] = key

        # Add a custom field with the current date
        e['entrydate'] = datetime.now().isoformat(timespec='minutes')

        # Select a full text file to go with the entry
        fn_local = _select_file(e['ID'], fn)
        if fn_local:
            e['localfile'] = os.path.basename(fn_local)

        # Append the entry to the database
        with open(ctx.database_fn, 'a') as f_imported:
            f_imported.write('\n')
            f_imported.write(to_string(e))

        # Write the abstract
        if abstract:
            fn_abstract = os.path.join(ctx.config['path'], 'abstracts',
                                       '%s.tex' % key)
            with open(fn_abstract, 'x') as f_abstract:
                f_abstract.write(abstract)

        # Move the full text file
        if fn_local:
            os.system('mv -n "{}" "{}"'.format(fn_local, e['localfile']))

        # Remove the imported entry file
        remove = input('\nRemove imported file %s ([Y]es, [enter] to '
                       'keep)? ' % fn)
        if remove.lower() == 'y':
            os.remove(fn)


def _check_files_plain(ok, other, missing, broken, files):
    print('OK: %d entries + matching files' % len(ok),
          '\t' + ' '.join(sorted(ok)),
          '',
          'OK: %d other entries by filter rules' % len(other),
          '\t' + ' '.join(sorted(other)),
          '',
          "Missing: %d entries w/o 'localfile' key" % len(missing),
          '\t' + '\n\t'.join(sorted(missing)),
          '',
          "Broken: %d entries w/ missing 'localfile'" % len(broken),
          '\n'.join(['\t{}\t→\t{}'.format(*e) for e in sorted(broken)]),
          '',
          'Not listed in any entry: %d files' % len(files),
          '\t' + '\n\t'.join(sorted(files)),
          sep='\n', end='\n')


def _check_files_csv(ok, other, missing, broken, files):
    lines = ['\t'.join(['ok', 'other', 'missing', 'broken', 'files'])]
    for group in zip_longest(ok, other, missing,
                             map(lambda x: '{} -> {}'.format(*x), broken),
                             files, fillvalue=''):
        lines.append('\t'.join(group))
    print('\n'.join(lines))


@cli.command()
@click.option('--format', 'fmt', type=click.Choice(['plain', 'csv']),
              default=None)
@pass_context
def check_files(ctx, fmt):
    """Check files listed in 'localfiles' fields.

    Configuration File Keys

    \b
    check_files:
      format: same as the --format option.
      ignore: list of glob patterns of paths to ignore.
      filter: list of triples, each with the following keys:
        field: BibLaTeX data model field, eg. 'keywords'
        value: string value to match
        sort: one of 'ok', 'other', 'missing' or 'broken': the list in which to
              place matching entries
    """
    # Get configuration options
    options = ctx.cmd_config('check_files')
    ignore = options.get('ignore', [])
    filters = options.get('filter', [])

    # Sets for recording entries:
    # - ok: has 'localfile' field, file exists
    # - other: hardcopies or online articles
    # - missing: no 'localfile' field
    # - broken: 'localfile' field exists, but is wrong
    sets = {k: set() for k in ['ok', 'other', 'missing', 'broken']}

    # Get the set of files in the current directory
    r = re.compile('(' + ')|('.join(ignore) + ')')
    files = filterfalse(os.path.isdir, iglob('**', recursive=True))
    files = sorted(filterfalse(r.search, files))

    # Iterate through database entries
    for e in ctx.db.entries:
        if e.has_file:
            if e.file_exists:
                sets['ok'].add(e['ID'])
                for fn in e.file_rel_path():
                    try:
                        files.remove(fn)
                    except ValueError:
                        if os.path.exists(fn):
                            # File exists, but has perhaps been filtered or
                            # is outside the tree.
                            continue
                        else:
                            raise
            else:
                sets['broken'] |= {(e['ID'], lf) for lf in e['localfile']}
        else:
            # Apply user filters
            done = False
            for f in filters:
                if f['field'] in e and f['value'] in e[f['field']]:
                    sets[f['sort']].add(e['ID'])
                    done = True
                    break
            if not done:
                sets['missing'].add(e['ID'])

    # Output
    output_format = options.get('format', 'csv') if fmt is None else fmt
    if output_format == 'plain':
        output = _check_files_plain
    elif output_format == 'csv':
        output = _check_files_csv
    output(sorted(sets['ok']), sorted(sets['other']),
           sorted(sets['missing']), sorted(sets['broken']),
           files)


@cli.command()
@pass_context
def curl(ctx):
    """Return args for `curl -K -` on 'url' fields.

    For each entry in the database, lines are output that specify the curl
    arguments --url, --output, and --time-cond. This output can be piped
    to
    """
    template = '\n'.join(['url="{0}"', 'output="{1}"', 'time-cond {1} '])

    for e in ctx.db.entries:
        url = e.get('url', None)
        localfile = e.get('localfile', None)
        if url is None or localfile is None:
            continue
        print(template.format(url, localfile[0]))


@cli.command('list')
@click.argument('field')
@click.option('--sort', is_flag=True)
@pass_context
def list_command(ctx, field, sort):
    """List all unique values of FIELD."""
    values = set()
    for e in ctx.db.entries:
        value = e.get(field, None)
        if value is None:
            continue
        elif not isinstance(value, list):
            value = [value]
        values |= set(value)

    if sort:
        values = sorted(values)

    print('\n'.join(values))


note_string = """Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.4
Creation-Date: {date}

====== {author} {year} ======
//{title}//
Created {date_text}

"""


@cli.command()
@click.argument('key')
@pass_context
def note_template(ctx, key):
    """Return a Zim note template for KEY."""
    from datetime import datetime, timezone
    entry = author(ctx.db.entries_dict.get(key, None))

    def surname(index):
        return entry['author'][index].split(',')[0]

    now = datetime.now(timezone.utc).astimezone().replace(microsecond=0)

    values = {
        'date': now.isoformat(),
        'date_text': now.strftime('%A %d %B %Y'),
        'year': entry['year'],
        'title': entry['title'],
        }

    if len(entry['author']) > 2:
        values['author'] = surname(0) + ' et al.'
    else:
        values['author'] = '{} & {}'.format(surname(0), surname(1))

    print(note_string.format(**values))


@cli.command('read')
@click.argument('key')
@pass_context
def read_command(ctx, key):
    """Open the 'localfile'(s) associated with KEY."""
    entry = ctx.db.entries_dict.get(key, None)

    if entry is None:
        raise ClickException("no entry with key '{}'.".format(key))
    elif 'localfile' not in entry:
        raise ClickException("entry '{}' has no localfile field."
                             .format(key))

    for fn in entry['localfile']:
        fn = os.path.join(ctx.config['path'], fn)
        os.system('xdg-open "{}"'.format(fn))


@cli.command()
@pass_context
def queue(ctx):
    """Display a reading queue.

    Entries matching the configuration value are considered to be part of a
    reading queue, sorted from lowest to highest according to priority.

    With --verbose/-v, *queue* also displays list of entries with no
    keywords; and with keywords but no queue match.


    Configuration File Keys

    \b
    queue:
      include: Required. A regular expression to match against values in each
               entry's 'keywords' field. Must contain a named group 'priority'
               that gives a sortable value indicating queue priority.
    """
    r = re.compile(ctx.cmd_config('queue').get('include', None))

    sets = {'no_kw': set(), 'no_queue': set(), 'to_read': list()}

    for e in ctx.db.entries:
        if 'keywords' in e:
            matches = list(filter(None,
                                  [r.match(kw) for kw in e['keywords']]))
            if len(matches) > 1:
                assert False
            elif len(matches) == 1:
                pri = matches[0].groupdict()['priority']
                sets['to_read'].append(('({0}) {1[ID]}: {1[title]}\n\t'
                                        '{1[localfile]}').format(pri, e))
            else:
                sets['no_queue'].add(e['ID'])
        else:
            sets['no_kw'].add(e['ID'])

    if ctx.verbose:
        print('No keywords: %d entries' % len(sets['no_kw']),
              '\t' + ' '.join(sorted(sets['no_kw'])),
              '',
              'Some keywords: %d entries' % len(sets['no_queue']),
              '\t' + ' '.join(sorted(sets['no_queue'])),
              sep='\n', end='\n\n')

    print('Read next:',
          '\n'.join(sorted(sets['to_read'])),
          sep='\n', end='\n\n')


@cli.command()
@click.option('--exclude-from', 'exclude', type=click.File('r'),
              help='Also omit keys from this file; one per line.')
@click.argument('other', type=click.Path(exists=True))
@pass_context
def diff(ctx, other, exclude):
    """Print keys in the database but not in OTHER."""
    keys = set(ctx.db.entries_dict.keys())

    other_db = ctx.read_database(other)
    keys -= set(other_db.entries_dict.keys())

    if exclude:
        keys -= set(exclude.read().split())

    print(*sorted(keys), sep='\n')


if __name__ == '__main__':
    cli()
