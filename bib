#!/usr/bin/env python3
"""BibTeX database utilities
© 2016–2017 Paul Natsuo Kishimoto <mail@paul.kishimoto.name>
Licensed under the GNU GPL v3.

Reads a file .bibpy.yaml in the current directory.
"""
from collections import namedtuple
from copy import deepcopy
from glob import iglob
from itertools import chain, filterfalse, zip_longest
import os
import os.path
import re
import readline

import bibtexparser
from bibtexparser.customization import author
from bibtexparser.bparser import BibTexParser
from bibtexparser.bwriter import BibTexWriter
import click
from click import ClickException
import yaml


DEFAULT_CONFIG = {
    'kw_sep': ',|;',
    'lf_sep': ';',
    }


class BibItem(dict):
    """Biliography items."""

    def __init__(self, record, add_keywords, config):
        # Parse 'keywords' to a list
        if 'keywords' in record:
            record['keywords'] = [kw.strip() for kw in
                                  re.split(config['kw_sep'],
                                           record['keywords'])]
            add_keywords(record['keywords'])

        # Parse 'localfile' to a list
        if 'localfile' in record:
            record['localfile'] = [lf.strip() for lf in
                                   re.split(config['lf_sep'],
                                            record['localfile'])]

        dict.__init__(self, record)
        self.type = self['ENTRYTYPE']

    @property
    def has_file(self):
        return 'localfile' in self

    @property
    def file_exists(self):
        if type(self['localfile']) == list:
            return all([os.path.exists(lf) for lf in self['localfile']])
        else:
            return os.path.exists(self['localfile'])

    def file_rel_path(self):
        if type(self['localfile']) == list:
            return [os.path.relpath(lf) for lf in self['localfile']]
        else:
            return os.path.relpath(self['localfile'])

    def stringify(self):
        """Convert all entries to strings.

        bibtexparser.bwriter.BibTexWriter requires all records in an item
        to be strings.
        """
        try:
            self['keywords'] = ';'.join(self['keywords'])
        except KeyError:
            pass


class BibCLIContext:
    def __init__(self):
        self.config = DEFAULT_CONFIG

        self.keywords = set()

    def init(self, database, verbose, path):
        try:
            config_fn = os.path.join(path, '.bibpy.yaml')
            with open(config_fn) as f:
                self.config.update(yaml.load(f))
            self.config['path'] = path
        except FileNotFoundError:
            pass

        self.verbose = verbose

        # Set up the BibTeX parser
        parser = BibTexParser()
        parser.homogenise_fields = False
        parser.ignore_nonstandard_types = False
        parser.customization = lambda r: BibItem(r,
                                                 self.keywords.update,
                                                 self.config)
        # Parse the database
        database = self.config.get('database', database)
        database_fn = os.path.join(path, database)
        self.db = bibtexparser.load(open(database_fn, 'r'),
                                    parser=parser)

    def cmd_config(self, cmd):
        return self.config.get(cmd, {})


# Custom decorator that uses BibCLIContext
pass_context = click.make_pass_decorator(BibCLIContext, ensure=True)


@click.group(help=__doc__)
@click.option('--database', type=click.Path('r'),
              help='Filename for the BibTeX database.')
@click.option('--verbose', is_flag=True, help='More detailed output.')
@click.option('--path', 'path', type=click.Path('r'),
              envvar='BIBPY_PATH', default='.',
              help='Path to the folder containing the database.')
@pass_context
def cli(ctx, database, verbose, path):
    # Initialize the context (load the database)
    ctx.init(database, verbose, path)


def _add_clean(d):
    """Custom entry cleaning for add()."""

    # Delete the leading text 'ABSTRACT'
    if 'abstract' in d and d['abstract'].lower().startswith('abstract'):
        d['abstract'] = d['abstract'][8:].strip()

    d['author'] = d['author'].replace('\n', ' ')

    if 'doi' in d:
        # Show a bare DOI, not a URL
        d['doi'] = re.sub('https?://(dx.)?doi.org/', '', d['doi'])
        # Don't show eprint or url fields if a DOI is present
        # (e.g ScienceDirect)
        d.pop('eprint', None)
        d.pop('url', None)

    # BibLaTeX: use 'journaltitle' for the name of the journal
    if 'journal' in d:
        d['journaltitle'] = d.pop('journal')

    if 'pages' in d:
        # Pages: use an en-dash
        d['pages'] = d['pages'].replace('--', '–').replace('-', '–') \
                               .replace(' ', '')

    # Delete any empty fields or those containing '0'
    for k in list(d.keys()):
        if d[k] in ['0', '']:
            del d[k]

    return d


def guess_key(entry):
    entry = author(deepcopy(entry))
    if len(entry['author']) > 2:
        a = entry['author'][0].split(',')[0].lower()
    else:
        a = '-'.join([a.split(',')[0].lower() for a in entry['author']])
    return '%s-%s' % (a, entry['year'])


def clean_str(s):
    # Add a trailing comma on the last entry:
    # https://github.com/sciunto-org/python-bibtexparser/issues/47
    s = re.sub(r'([^,])(\s*}\s*)\Z', r'\1,\2', s)
    # Compress multiple 'keywords'
    parts = re.split(r'(keywords)\s=\s[{"]([^}"]*)[}"],', s)
    result = ''
    keywords = []
    take = False
    for p in parts:
        if p == 'keywords':
            take = True
            continue
        elif take:
            keywords.append(p)
            take = False
            continue
        elif p.strip() == '':
            continue

        if len(keywords):
            result += 'keywords = {%s},' % '; '.join(keywords)
        print('part: <%s>' % p)
        result += p
    return result


# https://stackoverflow.com/a/8505387/2362198
def input_with_prefill(prompt, text):
    def hook():
        readline.insert_text(text)
        readline.redisplay()
    readline.set_pre_input_hook(hook)
    result = input(prompt)
    readline.set_pre_input_hook()
    return result


@cli.command(name='import')
@click.argument('paths', nargs=-1, type=click.Path(exists=True))
@pass_context
def import_entries(ctx, paths):
    """(DEV) Read new entries into the database.

    PATHS may be zero or more .bib files or directories containing .bib files
    to import.
    """
    # If no files or
    if len(paths) == 0:
        # Directory from which to import entries
        paths = [ctx.cmd_config('import').get('path', '.')]

    paths = [os.path.join(p, '*.bib') if os.path.isdir(p) else p
             for p in paths]

    # A parser for reading entries
    parser = BibTexParser()
    parser.homogenise_fields = False
    parser.customization = _add_clean

    # A writer for converting entries back to strings
    writer = BibTexWriter()
    writer.indent = '\t'

    # namedtuple to imitate a class with these attributes
    _dbnt = namedtuple('bdb', ['comments', 'entries', 'preambles', 'strings'])

    def to_string(entry):
        """Convert [entry] to a string."""
        # Create a fake 'database' with only one entry.
        return writer.write(_dbnt([], [entry], [], {}))

    # File for imported entries
    f_imported = open('added.bib', 'a')

    # Iterate over files in the add_dir
    for fn in chain(*map(iglob, paths)):
        os.system('clear')
        print('Importing', fn, end='\n\n')

        # Read and parse the file
        with open(fn, 'r') as f:
            s = f.read()
            e = parser.parse(clean_str(s)).entries[0]
            abstract = e.pop('abstract', None)

        print('Raw:', s)
        print('Entry:', to_string(e), sep='\n\n')

        if abstract is not None:
            print('Abstract:', abstract, sep='\n\n')

        # Ask user for a key
        while True:
            key = input_with_prefill('\nEnter key for imported entry '
                                     '(blank to skip, [Q]uit): ',
                                     guess_key(e))
            if key in ctx.db.entries_dict:
                print('Key already exists.')
            else:
                break

        if key == '':
            continue
        elif key.lower() == 'q':
            break
        else:
            # Change the entry key
            e['ID'] = key

        if abstract is not None:
            fn_abs = os.path.join('abstracts', '%s.tex' % key)
            with open(fn_abs, 'x') as f_abs:
                f_abs.write(abstract)

        f_imported.write(to_string(e))

        # Remove the imported file
        remove = input('\nRemove imported file %s ([Y]es, [enter] to keep)? '
                       % fn)
        if remove.lower() == 'y':
            os.remove(fn)


def _check_files_plain(ok, other, missing, broken, files):
    print('OK: %d entries + matching files' % len(ok),
          '\t' + ' '.join(sorted(ok)),
          '',
          'OK: %d other entries by filter rules' % len(other),
          '\t' + ' '.join(sorted(other)),
          '',
          "Missing: %d entries w/o 'localfile' key" % len(missing),
          '\t' + '\n\t'.join(sorted(missing)),
          '',
          "Broken: %d entries w/ missing 'localfile'" % len(broken),
          '\n'.join(['\t{}\t→\t{}'.format(*e) for e in sorted(broken)]),
          '',
          'Not listed in any entry: %d files' % len(files),
          '\t' + '\n\t'.join(sorted(files)),
          sep='\n', end='\n')


def _check_files_csv(ok, other, missing, broken, files):
    lines = ['\t'.join(['ok', 'other', 'missing', 'broken', 'files'])]
    for group in zip_longest(ok, other, missing,
                             map(lambda x: '{} -> {}'.format(*x), broken),
                             files, fillvalue=''):
        lines.append('\t'.join(group))
    print('\n'.join(lines))


@cli.command()
@click.option('--format', 'fmt', type=click.Choice(['plain', 'csv']),
              default=None)
@pass_context
def check_files(ctx, fmt):
    """Check files listed with the 'localfiles' fields."""
    # Get configuration options
    options = ctx.cmd_config('check-files')
    ignore = options.get('ignore', [])
    filters = options.get('filter', [])

    # Sets for recording entries:
    # - ok: has 'localfile' field, file exists
    # - other: hardcopies or online articles
    # - missing: no 'localfile' field
    # - broken: 'localfile' field exists, but is wrong
    sets = {k: set() for k in ['ok', 'other', 'missing', 'broken']}

    # Get the set of files in the current directory
    r = re.compile('(' + ')|('.join(ignore) + ')')
    files = filterfalse(os.path.isdir, iglob('**', recursive=True))
    files = sorted(filterfalse(r.search, files))

    # Iterate through database entries
    for e in ctx.db.entries:
        if e.has_file:
            if e.file_exists:
                sets['ok'].add(e['ID'])
                for fn in e.file_rel_path():
                    try:
                        files.remove(fn)
                    except ValueError:
                        if os.path.exists(fn):
                            # File exists, but has perhaps been filtered or
                            # is outside the tree.
                            continue
                        else:
                            raise
            else:
                sets['broken'] |= {(e['ID'], lf) for lf in e['localfile']}
        else:
            # Apply user filters
            done = False
            for f in filters:
                if f['field'] in e and f['value'] in e[f['field']]:
                    sets[f['sort']].add(e['ID'])
                    done = True
                    break
            if not done:
                sets['missing'].add(e['ID'])

    # Output
    output_format = options.get('format', 'csv') if fmt is None else fmt
    if output_format == 'plain':
        output = _check_files_plain
    elif output_format == 'csv':
        output = _check_files_csv
    output(sorted(sets['ok']), sorted(sets['other']),
           sorted(sets['missing']), sorted(sets['broken']),
           files)


@cli.command()
@pass_context
def kw_list(ctx):
    """List all keywords appearing in entries."""
    print('\n'.join(sorted(ctx.keywords)))


note_string = """Content-Type: text/x-zim-wiki
Wiki-Format: zim 0.4
Creation-Date: {date}

====== {author} {year} ======
//{title}//
Created {date_text}

"""


@cli.command()
@click.argument('key')
@pass_context
def note_template(ctx, key):
    """Return the template for a Zim note about entry KEY."""
    from datetime import datetime, timezone
    entry = author(ctx.db.entries_dict.get(key, None))

    def surname(index):
        return entry['author'][index].split(',')[0]

    now = datetime.now(timezone.utc).astimezone().replace(microsecond=0)

    values = {
        'date': now.isoformat(),
        'date_text': now.strftime('%A %d %B %Y'),
        'year': entry['year'],
        'title': entry['title'],
        }

    if len(entry['author']) > 2:
        values['author'] = surname(0) + ' et al.'
    else:
        values['author'] = '{} & {}'.format(surname(0), surname(1))

    print(note_string.format(**values))


@cli.command('read')
@click.argument('key')
@pass_context
def read_command(ctx, key):
    """Open the localfile(s) associated with KEY for reading."""
    entry = ctx.db.entries_dict.get(key, None)

    if entry is None:
        raise ClickException("no entry with key '{}'.".format(key))
    elif 'localfile' not in entry:
        raise ClickException("entry '{}' has no localfile field."
                             .format(key))

    for fn in entry['localfile']:
        fn = os.path.join(ctx.config['path'], fn)
        os.system('xdg-open "{}"'.format(fn))


@cli.command()
@pass_context
def queue(ctx):
    """Display a reading queue.

    The configuration value queue/include should contain a regular
    expression with one match group named 'priority'.

    When this matches against the keywords of a database entry, the
    entry is considered to be part of a reading queue, sorted from lowest
    to highest according to priority.

    With --verbose/-v, *queue* also displays list of entries with no
    keywords; and with keywords but no queue match.
    """
    r = re.compile(ctx.cmd_config('queue').get('include', None))

    sets = {'no_kw': set(), 'no_queue': set(), 'to_read': list()}

    for e in ctx.db.entries:
        if 'keywords' in e:
            matches = list(filter(None,
                                  [r.match(kw) for kw in e['keywords']]))
            if len(matches) > 1:
                assert False
            elif len(matches) == 1:
                pri = matches[0].groupdict()['priority']
                sets['to_read'].append(('({0}) {1[ID]}: {1[title]}\n\t'
                                        '{1[localfile]}').format(pri, e))
            else:
                sets['no_queue'].add(e['ID'])
        else:
            sets['no_kw'].add(e['ID'])

    if ctx.verbose:
        print('No keywords: %d entries' % len(sets['no_kw']),
              '\t' + ' '.join(sorted(sets['no_kw'])),
              '',
              'Some keywords: %d entries' % len(sets['no_queue']),
              '\t' + ' '.join(sorted(sets['no_queue'])),
              sep='\n', end='\n\n')

    print('Read next:',
          '\n'.join(sorted(sets['to_read'])),
          sep='\n', end='\n\n')


if __name__ == '__main__':
    cli()
